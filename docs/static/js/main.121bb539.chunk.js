(this["webpackJsonpsrijanduggal17.github.io"]=this["webpackJsonpsrijanduggal17.github.io"]||[]).push([[0],{27:function(e,t,s){},28:function(e,t,s){},34:function(e,t,s){},35:function(e,t,s){"use strict";s.r(t);var a=s(0),i=s(1),c=s.n(i),n=s(15),o=s.n(n),l=(s(27),s(7)),r=s(2),d=(s(28),s(16)),h=s(17),m=s(21),j=s(19),b=function(e){Object(m.a)(s,e);var t=Object(j.a)(s);function s(){return Object(d.a)(this,s),t.apply(this,arguments)}return Object(h.a)(s,[{key:"render",value:function(){var e=this.props,t=(e.match,e.location),s=(e.history,t.pathname===this.props.to?"nav-link active":"nav-link");return Object(a.jsx)(l.b,{to:this.props.to,className:s,exact:this.props.exact,children:this.props.children})}}]),s}(c.a.Component),p=Object(r.g)(b);function u(e){return Object(a.jsx)("nav",{className:"navbar navbar-expand-lg navbar-light bg-light",children:Object(a.jsxs)("div",{className:"container-fluid",children:[Object(a.jsx)("a",{className:"navbar-brand fs-3",href:"/",children:"Srijan Duggal"}),Object(a.jsx)("button",{className:"navbar-toggler",type:"button","data-bs-toggle":"collapse","data-bs-target":"#navbarNavAltMarkup","aria-controls":"navbarNavAltMarkup","aria-expanded":"false","aria-label":"Toggle navigation",children:Object(a.jsx)("span",{className:"navbar-toggler-icon"})}),Object(a.jsx)("div",{className:"collapse navbar-collapse",id:"navbarNavAltMarkup",style:{fontWeight:"bold"},children:Object(a.jsxs)("ul",{className:"nav navbar-nav",style:{marginLeft:"auto"},children:[Object(a.jsx)(p,{to:"/projects",children:"Projects"}),Object(a.jsx)(p,{to:"/",children:"About Me"}),Object(a.jsx)(p,{to:"/contact",children:"Contact Me"})]})})]})})}function g(e){return Object(a.jsxs)("div",{className:"w-100",style:{backgroundColor:"#99B9CC"},children:[Object(a.jsx)("h3",{className:"pt-5 pb-5 text-center",children:"welcome"}),Object(a.jsx)("p",{className:"m-auto text-center w-75 pb-5",children:"My name is Srijan Duggal. I'm an avid learner and my mission is to help people through my creations (hardware and software). I'm a Mechanical Engineer by training, but my passion for learning has led me to proficiency in a variety of skillsets. Check out some of my cool projects!"})]})}var x=s(20);s(34);function f(e){var t=Object(r.f)().url;return Object(a.jsx)("div",{className:"col thumbcard",children:Object(a.jsxs)(l.b,{to:"".concat(t,"/").concat(e.projectURL),children:[Object(a.jsx)("img",{src:"thumbnails/".concat(e.imgPath),style:{width:"100%"}}),Object(a.jsxs)("div",{className:"thumbtext",children:[Object(a.jsx)("p",{className:"text-center display-7 fs-4",children:e.title}),Object(a.jsx)("p",{className:"text-center",children:e.desc}),Object(a.jsx)("p",{className:"text-end fst-italic",children:e.timeline}),Object(a.jsx)("p",{className:"bottom-align-text skills fw-bold",children:e.skills.join(", ")})]})]})})}function w(e){var t={maxHeight:"60vh",maxWidth:"100%"};return Object(a.jsxs)("div",{children:[Object(a.jsx)("p",{className:"text-center display-4 pt-2 pb-6",children:"2048 Playing Agent"}),Object(a.jsxs)("div",{className:"w-100 container-fluid",children:[Object(a.jsxs)("div",{className:"row",style:{backgroundColor:"#f3b27a"},children:[Object(a.jsx)("div",{className:"col-sm-3",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/2048/2048 Game.png",style:t})}),Object(a.jsx)("div",{className:"col text-center fs-4 fw-bold d-flex align-items-center",style:{color:"white"},children:Object(a.jsx)("p",{children:"I made a bot to play this online game called 2048. I had it choose actions based on two sets of rules: one that my friend and I came up with and one that it tried to learn using reinforcement learning."})})]}),Object(a.jsxs)("div",{className:"row",style:{backgroundColor:"#eee4da"},children:[Object(a.jsx)("div",{className:"col text-start fs-5 d-flex align-items-center pt-4",style:{color:"#786e66"},children:Object(a.jsx)("p",{children:"When I was in high school, I used to play this game. The way it works is you have a tile area and the goal is to create a 2048 tile. You can press the left/right/up/down arrow keys, and when you do, each tile moves in the direction you pressed until it hits another tile. If it hits a tile of equal value, then the two tiles combine and the value doubles: when a 2 tile and a 2 tile collide, they become a 4 tile. Every time you move, a 2 or 4 tile is randomly added to the board."})}),Object(a.jsx)("div",{className:"col-sm-4",children:Object(a.jsx)("img",{className:"pt-4 mx-auto pb-4 d-block",src:"https://thumbs.gfycat.com/ImpassionedShadyFlounder-small.gif",style:t})})]}),Object(a.jsxs)("div",{className:"row",style:{backgroundColor:"#f77c5f"},children:[Object(a.jsx)("div",{className:"col-sm-6",children:Object(a.jsx)("iframe",{className:"pt-4 mx-auto pb-4 d-block",src:"https://www.youtube.com/embed/H8oM8vUvROc",style:{height:"80vh",width:"100%"}})}),Object(a.jsx)("div",{className:"col text-start d-flex fs-5 align-items-center pt-4",style:{color:"white"},children:Object(a.jsxs)("p",{children:["This was a common game amongst kids in my school, and after learning about reinforcement learning during my Deep Learning class, I thought it would be fun to make a bot that could play. I started by using ",Object(a.jsx)("span",{className:"fw-bold",children:"Selenium"})," and ",Object(a.jsx)("span",{className:"fw-bold",children:"Python"})," to scrape the game website, and to get the values of the tiles as well as the score. Once I had made a way to interact with the website using Python functions, I started working on two agents. The first agent played the game according to a set of rules that my friend and I created. The second agent played the game using a learned policy (from Deep Reinforcement Learning). My friend and I played many games and thought about what we would do in various situations to come up with rules to beat it. Eventually we were able to come up with a policy that almost guaranteed winning, at least as frequently as we would win if we were playing (see video)."]})})]}),Object(a.jsx)("div",{className:"row",style:{backgroundColor:"#eee1c9"},children:Object(a.jsx)("div",{className:"col text-start fs-5",children:Object(a.jsxs)("p",{className:"w-100 mx-auto pt-4",children:["For the Reinforcement Learning agent, I used some convolution layers and a feed-forward neural network. For the reward function, I used the score and tried training the agent. After training for a while, it was able to do some moves that seemed like things my friend and I would do, but it lost well before reaching 2048. I didn\u2019t have any experience in reinforcement learning at this time, so I wasn\u2019t really sure how to move forward. Looking back on it now (I still haven\u2019t gained any experience in reinforcement learning since then, but I have done more deep learning projects using convolutional neural networks), I think it needed more training time and potentially a different reward function. While I did not finish training a successful reinforcement learning agent, I was able to interact with the game website and use ",Object(a.jsx)("span",{className:"fw-bold",children:"PyTorch"})," in real-time to play it, which to me was a success. One day I would like to revisit this and finish training an agent that can win!"]})})}),Object(a.jsxs)("div",{className:"row fs-5",children:[Object(a.jsx)("div",{className:"col text-center pt-4",children:Object(a.jsxs)("p",{children:["The game can be found at ",Object(a.jsx)("a",{href:"https://play2048.co/",children:"https://play2048.co/"})]})}),Object(a.jsx)("div",{className:"col-sm-6 text-center pt-4 text-break",children:Object(a.jsxs)("p",{children:["GIF credits: ",Object(a.jsx)("a",{href:"https://gfycat.com/impassionedshadyflounder",children:"https://gfycat.com/impassionedshadyflounder"})]})})]})]}),Object(a.jsx)("p",{})]})}function O(e){return Object(a.jsx)("p",{className:"pt-4 text-center display-5",children:e.children})}function v(e){return Object(a.jsx)("div",{className:"row",children:Object(a.jsx)("div",{className:"col mx-auto col-11 text-start d-flex fs-5 align-items-center pt-4",children:Object(a.jsx)("p",{children:e.children})})})}function y(e){var t={backgroundColor:"white"},s={backgroundColor:"white"},i={maxHeight:"60vh",maxWidth:"100%"},c={maxHeight:"70vh",maxWidth:"100%"},n={color:"black"},o={color:"black"};return Object(a.jsxs)("div",{children:[Object(a.jsx)("p",{className:"text-center display-4 pt-2 pb-6",children:"Knee Exoskeleton Controller"}),Object(a.jsxs)("div",{className:"w-100 container-fluid",children:[Object(a.jsxs)("div",{className:"row",style:t,children:[Object(a.jsx)("div",{className:"col-sm-3",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Knee Exo.jpg",style:i})}),Object(a.jsx)("div",{className:"col text-center fs-4 fw-bold d-flex align-items-center",style:{color:"grey"},children:Object(a.jsx)("p",{children:"This project was part of my undergraduate research at the Exoskeleton and Prosthetics Intelligent Controls (EPIC) Lab with Dr. Aaron Young. I worked on it for two semesters with another undergrad student and learned a lot about working with electronics and sensors for control."})})]}),Object(a.jsxs)("div",{className:"row",style:s,children:[Object(a.jsx)("div",{className:"col text-start fs-5 d-flex align-items-center pt-4",style:n,children:Object(a.jsx)("p",{children:"Some context: the EPIC lab has a focus on devices that humans wear to assist their motion. This project was based on assisting soldiers in walking long distances while carrying their heavy gear. The device was developed by Dr. Frank Hammond\u2019s lab, and our two goals were to control how the device assists the user, and to make it user-friendly. I was excited for the opportunity to gain hands-on technical experience with a project of this scope."})}),Object(a.jsx)("div",{className:"col-sm-4",children:Object(a.jsx)("img",{className:"pt-4 mx-auto pb-4 d-block",src:"project-assets/Knee Exo/Epic Logo.jpg",style:i})})]}),Object(a.jsxs)("div",{className:"row",style:s,children:[Object(a.jsx)("div",{className:"col-sm-6",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Nextflex Device.png",style:i})}),Object(a.jsx)("div",{className:"col text-start d-flex fs-5 align-items-center pt-4",style:n,children:Object(a.jsx)("p",{children:"At a high level, the device can produce a torque about the knee joint by expanding or contracting two pairs of pneumatic \u201cmuscles\u201d (this is how it helps you walk). The device needs to know how much torque to assist you with at any time. We determined this by measuring the electrical activity of the user\u2019s muscles (this is related to how much the muscle is about to contract) and commanding a torque proportional to this. To make the device user-friendly, we developed a control handle with buttons, switches, and LEDs to allow the user to change the mode that the device was operating in."})})]}),Object(a.jsx)(O,{children:"User Interface"}),Object(a.jsxs)("div",{className:"row",style:t,children:[Object(a.jsx)("div",{className:"col text-start d-flex fs-5 align-items-center pt-4",style:o,children:Object(a.jsx)("p",{children:"The user can control the device \u2013 turning the controller on, calibrating the controller, and setting the device to provide assistance \u2013 all using the simple handle with LED feedback. We designed a PCB for easy mounting of the electronics and a handle to house it."})}),Object(a.jsx)("div",{className:"col-sm-6 d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Nextflex Handle.png",style:i})})]}),Object(a.jsx)(O,{children:"Hardware"}),Object(a.jsxs)("div",{className:"row",children:[Object(a.jsx)("div",{className:"col-sm-6 d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Nextflex Hardware.png",style:c})}),Object(a.jsx)("div",{className:"col text-start d-flex fs-5 align-items-center pt-4",style:o,children:Object(a.jsx)("p",{children:"The brain of the device is a Raspberry Pi microprocessor, which reads from two sensors: EMG and encoder. The encoder provides information on the angular position of the knee joint, and the EMG captures the muscle activity. The Raspberry Pi only takes digital inputs, so an Analog to Digital Converter (ADC) was necessary to read the EMG signals. The ADC had an SPI communication protocol output, so I learned about how to read this at a low-level and convert the digital pulses to the signal we desired. The digital encoder had a logic level of 5V, but the Raspberry Pi operates on a 3.3V logic level, so a level converter was necessary. The TI Launchpad was provided to us on the device itself, and it performed the low level pressure control in the muscles. We had to communicate with it using the UART protocol."})})]}),Object(a.jsxs)("div",{className:"row",children:[Object(a.jsx)("div",{className:"col-sm-5 d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/RPi Shield Schematic.png",style:c})}),Object(a.jsx)("div",{className:"col-sm-4 d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/RPi Shield Layout.png",style:c})}),Object(a.jsx)("div",{className:"col-sm-3 d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/RPi Shield Prototype.jpg",style:c})})]}),Object(a.jsx)(v,{children:"Once an initial circuit was functional on a breadboard, we designed a PCB shield to sit on top of the Raspberry Pi for a compact profile. The PCB was designed in Autodesk Eagle and then fabricated in The Hive makerspace at Georgia Tech. After we tested the PCB shield using a function generator/oscilloscope and then on the actual Raspberry Pi, we ordered a more professional board from OshPark. Finally, I designed a case for the Raspberry Pi and shield in SolidWorks and 3D printed it."}),Object(a.jsxs)("div",{className:"row",children:[Object(a.jsx)("div",{className:"col-sm-6 d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/RPi Shield.png",style:c})}),Object(a.jsx)("div",{className:"col d-flex align-items-center",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/RPi Shield and Case.jpg",style:c})})]}),Object(a.jsx)(O,{children:"Device Logic and Framework"}),Object(a.jsx)(v,{children:"The logic for the different operating modes of the device (powered on, calibrating, calibrated, and assisting) and the controller was implemented on the Raspberry Pi using Python and ROS. This was my first exposure to ROS, and while I did not lead that aspect of the project, I learned about its purpose, capabilities, and how to use it. A diagram for the ROS nodes we used as well as a state transition diagram for the device are shown."}),Object(a.jsx)("div",{className:"row",children:Object(a.jsx)("div",{className:"col",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/State Machine.png",style:c})})}),Object(a.jsx)("div",{className:"row",children:Object(a.jsx)("div",{className:"col",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/ROS Nodes.png",style:{maxHeight:"80vh",maxWidth:"100%"}})})}),Object(a.jsx)(O,{children:"Proportional Myoelectric Controller Implementation"}),Object(a.jsx)(v,{children:"The actual controller that determined the commanded assistance torque was a Proportional Myoelectric Controller, adapted from Koller et al[1]. The raw EMG signal is noisy and we wanted the torque profile to be proportional to the overall EMG profile. To create the EMG profile, at any clock cycle of the controller, the RMS of a backward-looking window of the EMG signal was calculated. This created a smooth time series with which we could command the device. The RMS EMG at each clock cycle was compared to the maximum RMS EMG value during the calibration phase to produce the desired torque output (See Equation 1). Essentially, the torque command is a fraction of the device\u2019s maximum torque, and this fraction is determined by the current EMG signal."}),Object(a.jsx)("div",{className:"row",children:Object(a.jsx)("div",{className:"mx-auto col-sm-6",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Controller Eqn.png",style:i})})}),Object(a.jsx)(v,{children:"A time series example of what this looks like is shown. This was from an offline computation of the output torque, but the real-time result is the same."}),Object(a.jsxs)("div",{className:"row",children:[Object(a.jsx)("div",{className:"col",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Controller Offline.png",style:c})}),Object(a.jsx)("div",{className:"col mx-auto text-start d-flex fs-5 align-items-center pt-4",children:Object(a.jsx)("p",{children:"When the EMG signal is flat, the user\u2019s muscles are in a resting state, however there are still slight torque output values. It is undesirable for the device to be attempting to assist at an almost negligible torque, so during the calibration phase, a threshold RMS EMG level is also calculated."})})]}),Object(a.jsx)(O,{children:"Calibration"}),Object(a.jsx)(v,{children:"The purpose of the calibration phase is to calculate two quantities: the threshold RMS EMG level, and the maximum RMS EMG level. After the user presses the calibration button, they must walk for a short period of time during which the device is recording the device data. This is where the knee encoder is used. We used the fact that walking is a periodic motion to detect a fixed number of gait cycles before computing the two quantities. The encoder signal has some drift, but we found that a peak detection function from the scipy library was sufficient to detect local minima in the series. Once 7 gait cycles had passed, we computed the RMS EMG profile and calculated the maximum (for use in the torque command equation) and the 10th percentile (for use as a threshold to eliminate noise when the muscle is resting)."}),Object(a.jsxs)("div",{className:"row",children:[Object(a.jsx)("div",{className:"col",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Encoder vs Time.png",style:i})}),Object(a.jsx)("div",{className:"col",children:Object(a.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/Knee Exo/Threshold Ex.png",style:i})})]}),Object(a.jsx)(v,{children:"1. Koller, J.R., Jacobs, D.A., Ferris, D.P. et al. Learning to walk with an adaptive gain proportional myoelectric controller for a robotic ankle exoskeleton. J NeuroEngineering Rehabil 12, 97 (2015). https://doi.org/10.1186/s12984-015-0086-5"})]}),Object(a.jsx)("p",{})]})}var N=[{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048 using human-based logic & reinforcement learning",timeline:"June-July 2020",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(a.jsx)(w,{})},{imgPath:"Knee Exo.jpg",title:"Knee Exoskeleton Controller",desc:"Implemented hardware/software for pneumatic knee exoskeleton control",timeline:"Jan-Dec 2020",skills:["microcontrollers","PCB design","ROS"],projectURL:"knee-exo",projectPage:Object(a.jsx)(y,{})},{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048: human-based logic and reinforcement learning",timeline:"May-June 2019",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(a.jsx)(w,{})},{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048: human-based logic and reinforcement learning",timeline:"May-June 2019",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(a.jsx)(w,{})}];function k(e){return Object(a.jsx)("div",{className:"container-md",children:Object(a.jsx)("div",{className:"row",children:N.map((function(e){return Object(a.jsx)(f,Object(x.a)({},e))}))})})}function E(e){return Object(a.jsx)("div",{children:Object(a.jsx)("p",{children:"Let's get in touch"})})}var P=function(){return Object(a.jsx)(l.a,{children:Object(a.jsxs)("div",{style:{minHeight:"100vh"},children:[Object(a.jsx)(u,{}),Object(a.jsxs)(r.c,{children:[N.map((function(e){return Object(a.jsx)(r.a,{path:"/projects/".concat(e.projectURL),children:e.projectPage})})),Object(a.jsx)(r.a,{path:"/projects",children:Object(a.jsx)(k,{})}),Object(a.jsx)(r.a,{path:"/contact",children:Object(a.jsx)(E,{})}),Object(a.jsx)(r.a,{exact:!0,path:"/",children:Object(a.jsx)(g,{})})]})]})})};o.a.render(Object(a.jsx)(c.a.StrictMode,{children:Object(a.jsx)(P,{})}),document.getElementById("root"))}},[[35,1,2]]]);
//# sourceMappingURL=main.121bb539.chunk.js.map