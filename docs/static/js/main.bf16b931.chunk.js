(this["webpackJsonpsrijanduggal17.github.io"]=this["webpackJsonpsrijanduggal17.github.io"]||[]).push([[0],{27:function(e,t,a){},28:function(e,t,a){},34:function(e,t,a){},35:function(e,t,a){"use strict";a.r(t);var n=a(0),s=a(1),i=a.n(s),c=a(15),r=a.n(c),l=(a(27),a(7)),o=a(2),d=(a(28),a(16)),h=a(17),j=a(21),b=a(19),m=function(e){Object(j.a)(a,e);var t=Object(b.a)(a);function a(){return Object(d.a)(this,a),t.apply(this,arguments)}return Object(h.a)(a,[{key:"render",value:function(){var e=this.props,t=(e.match,e.location),a=(e.history,t.pathname===this.props.to?"nav-link active":"nav-link");return Object(n.jsx)(l.b,{to:this.props.to,className:a,exact:this.props.exact,children:this.props.children})}}]),a}(i.a.Component),g=Object(o.g)(m);function u(e){return Object(n.jsx)("nav",{className:"navbar navbar-expand-lg navbar-light bg-light",children:Object(n.jsxs)("div",{className:"container-fluid",children:[Object(n.jsx)("a",{className:"navbar-brand fs-3",href:"/",children:"Srijan Duggal"}),Object(n.jsx)("button",{className:"navbar-toggler",type:"button","data-bs-toggle":"collapse","data-bs-target":"#navbarNavAltMarkup","aria-controls":"navbarNavAltMarkup","aria-expanded":"false","aria-label":"Toggle navigation",children:Object(n.jsx)("span",{className:"navbar-toggler-icon"})}),Object(n.jsx)("div",{className:"collapse navbar-collapse",id:"navbarNavAltMarkup",style:{fontWeight:"bold"},children:Object(n.jsxs)("ul",{className:"nav navbar-nav",style:{marginLeft:"auto"},children:[Object(n.jsx)(g,{to:"/projects",children:"Projects"}),Object(n.jsx)(g,{to:"/",children:"About Me"}),Object(n.jsx)(g,{to:"/contact",children:"Contact Me"})]})})]})})}function p(e){return Object(n.jsxs)("div",{className:"w-100",style:{backgroundColor:"#99B9CC"},children:[Object(n.jsx)("h3",{className:"pt-5 pb-5 text-center",children:"welcome"}),Object(n.jsx)("p",{className:"m-auto text-center w-75 pb-5",children:"My name is Srijan Duggal. I'm an avid learner and my mission is to help people through my creations (hardware and software). I'm a Mechanical Engineer by training, but my passion for learning has led me to proficiency in a variety of skillsets. Check out some of my cool projects!"})]})}var x=a(20);a(34);function f(e){var t=Object(o.f)().url;return Object(n.jsx)("div",{className:"col thumbcard",children:Object(n.jsxs)(l.b,{to:"".concat(t,"/").concat(e.projectURL),children:[Object(n.jsx)("img",{src:"thumbnails/".concat(e.imgPath),style:{width:"100%"}}),Object(n.jsxs)("div",{className:"thumbtext",children:[Object(n.jsx)("p",{className:"text-center display-6",children:e.title}),Object(n.jsx)("p",{className:"text-center",children:e.desc}),Object(n.jsx)("p",{className:"text-end",children:e.timeline}),Object(n.jsx)("p",{className:"bottom-align-text skills",children:e.skills.join(", ")})]})]})})}function y(e){var t={maxHeight:"60vh"};return Object(n.jsxs)("div",{children:[Object(n.jsx)("p",{className:"text-center display-4 pt-2 pb-6",children:"2048 Playing Agent"}),Object(n.jsxs)("div",{className:"w-100 container-fluid",children:[Object(n.jsxs)("div",{className:"row",style:{backgroundColor:"#f3b27a"},children:[Object(n.jsx)("div",{className:"col-3",children:Object(n.jsx)("img",{className:"pt-4 pb-4 mx-auto d-block",src:"project-assets/2048/2048 Game.png",style:t})}),Object(n.jsx)("div",{className:"col text-center fs-4 fw-bold d-flex align-items-center",style:{color:"white"},children:Object(n.jsx)("p",{children:"I made a bot to play this online game called 2048. I had it choose actions based on two sets of rules: one that my friend and I came up with and one that it tried to learn using reinforcement learning."})})]}),Object(n.jsxs)("div",{className:"row",style:{backgroundColor:"#eee4da"},children:[Object(n.jsx)("div",{className:"col text-center d-flex align-items-center",style:{color:"#786e66"},children:Object(n.jsx)("p",{children:"When I was in high school, I used to play this game. The way it works is you have a tile area and the goal is to create a 2048 tile. You can press the left/right/up/down arrow keys, and when you do, each tile moves in the direction you pressed until it hits another tile. If it hits a tile of equal value, then the two tiles combine and the value doubles: when a 2 tile and a 2 tile collide, they become a 4 tile. Every time you move, a 2 or 4 tile is randomly added to the board."})}),Object(n.jsx)("div",{className:"col-4",children:Object(n.jsx)("img",{className:"pt-4 mx-auto pb-4 d-block",src:"https://thumbs.gfycat.com/ImpassionedShadyFlounder-small.gif",style:t})})]}),Object(n.jsxs)("div",{className:"row",style:{backgroundColor:"#f77c5f"},children:[Object(n.jsx)("div",{className:"col",children:Object(n.jsx)("iframe",{className:"pt-4 mx-auto pb-4 d-block",src:"https://www.youtube.com/embed/H8oM8vUvROc",style:{height:"80vh",width:"100%"}})}),Object(n.jsx)("div",{className:"col text-center d-flex align-items-center",style:{color:"white"},children:Object(n.jsxs)("p",{children:["This was a common game amongst kids in my school, and after learning about reinforcement learning during my Deep Learning class, I thought it would be fun to make a bot that could play. I started by using ",Object(n.jsx)("span",{className:"fw-bold",children:"Selenium"})," and ",Object(n.jsx)("span",{className:"fw-bold",children:"Python"})," to scrape the game website, and to get the values of the tiles as well as the score. Once I had made a way to interact with the website using Python functions, I started working on two agents. The first agent played the game according to a set of rules that my friend and I created. The second agent played the game using a learned policy (from Deep Reinforcement Learning). My friend and I played many games and thought about what we would do in various situations to come up with rules to beat it. Eventually we were able to come up with a policy that almost guaranteed winning, at least as frequently as we would win if we were playing (see video)."]})})]}),Object(n.jsx)("div",{className:"row",style:{backgroundColor:"#eee1c9"},children:Object(n.jsx)("div",{className:"col text-center",children:Object(n.jsxs)("p",{className:"w-75 mx-auto pt-4",children:["For the Reinforcement Learning agent, I used some convolution layers and a feed-forward neural network. For the reward function, I used the score and tried training the agent. After training for a while, it was able to do some moves that seemed like things my friend and I would do, but it lost well before reaching 2048. I didn\u2019t have any experience in reinforcement learning at this time, so I wasn\u2019t really sure how to move forward. Looking back on it now (I still haven\u2019t gained any experience in reinforcement learning since then, but I have done more deep learning projects using convolutional neural networks), I think it needed more training time and potentially a different reward function. While I did not finish training a successful reinforcement learning agent, I was able to interact with the game website and use ",Object(n.jsx)("span",{className:"fw-bold",children:"PyTorch"})," in real-time to play it, which to me was a success. One day I would like to revisit this and finish training an agent that can win!"]})})}),Object(n.jsxs)("div",{className:"row",children:[Object(n.jsx)("div",{className:"col text-center",children:Object(n.jsxs)("p",{children:["GIF credits: ",Object(n.jsx)("a",{href:"https://gfycat.com/impassionedshadyflounder",children:"https://gfycat.com/impassionedshadyflounder"})]})}),Object(n.jsx)("div",{className:"col text-center",children:Object(n.jsxs)("p",{children:["The game can be found at ",Object(n.jsx)("a",{href:"https://play2048.co/",children:"https://play2048.co/"})]})})]})]}),Object(n.jsx)("p",{})]})}var O=[{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048: human-based logic and reinforcement learning",timeline:"May-June 2019",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(n.jsx)(y,{})},{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048: human-based logic and reinforcement learning",timeline:"May-June 2019",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(n.jsx)(y,{})},{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048: human-based logic and reinforcement learning",timeline:"May-June 2019",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(n.jsx)(y,{})},{imgPath:"2048 Game.png",title:"2048 Playing Agent",desc:"Bot that plays 2048: human-based logic and reinforcement learning",timeline:"May-June 2019",skills:["web scraping","reinforcement learning"],projectURL:"2048Agent",projectPage:Object(n.jsx)(y,{})}];function w(e){return Object(n.jsx)("div",{className:"container-md",children:Object(n.jsx)("div",{className:"row",children:O.map((function(e){return Object(n.jsx)(f,Object(x.a)({},e))}))})})}function v(e){return Object(n.jsx)("div",{children:Object(n.jsx)("p",{children:"Let's get in touch"})})}var N=function(){return Object(n.jsx)(l.a,{children:Object(n.jsxs)("div",{style:{minHeight:"100vh"},children:[Object(n.jsx)(u,{}),Object(n.jsxs)(o.c,{children:[O.map((function(e){return Object(n.jsx)(o.a,{path:"/projects/".concat(e.projectURL),children:e.projectPage})})),Object(n.jsx)(o.a,{path:"/projects",children:Object(n.jsx)(w,{})}),Object(n.jsx)(o.a,{path:"/contact",children:Object(n.jsx)(v,{})}),Object(n.jsx)(o.a,{exact:!0,path:"/",children:Object(n.jsx)(p,{})})]})]})})};r.a.render(Object(n.jsx)(i.a.StrictMode,{children:Object(n.jsx)(N,{})}),document.getElementById("root"))}},[[35,1,2]]]);
//# sourceMappingURL=main.bf16b931.chunk.js.map